# -*- coding: utf-8 -*-
"""CaliforniaHousing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FjN5b1AN93kKwQLusnebm01PP7AQ9cun
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats
import seaborn as sns
from sklearn.impute import SimpleImputer

# Import dataset
df = pd.read_csv("housing.csv")

"""# Check Dataset"""

df.head()

"""The dataset consists of 9 features + 1 target (median_house_value):
Longitude: geographic coordinate that specifies the east–west position of the block
Latitude: geographic coordinate that specifies the north–south position of the block
housingMedianAge: Median age of houses in a block
totalRooms: Total number of rooms within a block
totalBedrooms: Total number of bedrooms within a block
population: Total number of people residing within a block
households: Total number of households for a block
medianIncome: Median income for households within a block of houses (measured in tens of thousands of US Dollars)
medianHouseValue: Median house value for households within a block (measured in US Dollars) --> TARGET
oceanProximity: distance from the ocean the ocean the ocean
"""

df.info()

"""__This dataset contains 9 numerical feature and 1 object__"""

df.shape

df.size

df.describe().T

"""# Check Data & Datatypes"""

# Check values of "Ocean_proximity"
df['ocean_proximity'].value_counts()

# Checking NaN Values
df.isnull().sum()

# Searchin for those rows with NaN 'total_bedrooms'
df[(df['total_bedrooms'].isnull())]

# Filling missing values of total_bedrooms
imputer = SimpleImputer(strategy='mean')
df['total_bedrooms'] = imputer.fit_transform(df[['total_bedrooms']])

# Check Duplicate Values
df.duplicated().sum()

# Checking the mean,median, count of features based on "ocean_proximity"
df_ocean_proximity = df.groupby("ocean_proximity")[['housing_median_age', 'total_rooms', 'total_bedrooms', 'median_house_value']].agg(['count', 'mean', 'median'])
df_ocean_proximity

"""# Correlation Matrix"""

corr_matrix = df.corr(numeric_only=True)
plt.figure(figsize=(12, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('Correlation Matrix')
plt.show()

"""longitude & latitude: There is a strong negative correlation (-0.92) between longitude and latitude, indicating that locations with higher longitude tend to have lower latitude, and vice versa. This suggests a spatial pattern in the data.

housing_median_age & median_income: There is a weak negative correlation (-0.12) between housing median age and median income. This suggests that areas with older housing tend to have slightly lower median incomes.

total_rooms & total_bedrooms: There is a strong positive correlation (0.93) between total rooms and total bedrooms, indicating that areas with more rooms tend to have more bedrooms, which is expected.

population & households: There is a strong positive correlation (0.91) between population and households, indicating that areas with larger populations tend to have more households.

median_income & median_house_value: There is a moderately strong positive correlation (0.69) between median income and median house value. This suggests that areas with higher median incomes tend to have higher median house values. values.

# Check Distribution
"""

def distribution(col):
    plt.figure(figsize=(12, 6))
    plt.hist(df[col], bins=150, color='red', rwidth=0.8, edgecolor='black')
    plt.title(f"Distribuition of {col}")
    plt.xlabel(f"{col}")
    plt.ylabel("Frequency")
    plt.show()

columns = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',
       'total_bedrooms', 'population', 'households', 'median_income',
       'median_house_value']

for col in columns:
    distribution(col)

"""# General Overview of features distribution"""

df.hist(figsize=(16, 10), bins=150)
plt.tight_layout()
plt.show()

"""# Boxplot of features"""

def boxplot(col, save_path=None):
    plt.figure(figsize=(12, 6))
    sns.boxplot(x=df[col], color='skyblue')
    plt.title(f"{col} Boxplot", fontsize=16)
    plt.xlabel(f"{col}", fontsize=14)
    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)
    plt.show()

for col in columns:
    boxplot(col)

"""# Barplot of `ocean_proximity`"""

plt.figure(figsize=(8, 6))
df['ocean_proximity'].value_counts().plot(kind='bar', color='skyblue')
plt.xlabel('Ocean Proximity')
plt.ylabel('Count')
plt.title('Bar Plot of Ocean Proximity')
plt.show()

"""# Scatter Plot of columns Vs `median_house_value`"""

def plot_scatter(df, columns):
    target_col = 'median_house_value'
    num_cols = len(columns)
    fig, axes = plt.subplots(nrows=1, ncols=num_cols, figsize=(4*num_cols, 4))
    fig.subplots_adjust(hspace=0.4, wspace=0.4)

    for i, col in enumerate(columns):
        sns.scatterplot(data=df, x=col, y=target_col, ax=axes[i])
        axes[i].set_title(f'Scatter plot of {col} vs {target_col}')
        axes[i].set_xlabel(col)
        axes[i].set_ylabel(target_col)

    plt.show()

plot_scatter(df, columns)

"""# Pairplot"""

def plot_correlation(df):
    sns.set(style="ticks")
    sns.pairplot(df)
    plt.show()

# Usage example:
plot_correlation(df)



import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

def plot_regression(df, x_col, y_col):
    # Extracting features and target
    X = df[x_col].values.reshape(-1, 1)
    y = df[y_col].values.reshape(-1, 1)

    # Fitting the linear regression model
    model = LinearRegression()
    model.fit(X, y)

    # Predicting the target values
    y_pred = model.predict(X)

    # Plotting the actual data points
    plt.scatter(X, y, color='blue', label='Actual')

    # Plotting the regression line
    plt.plot(X, y_pred, color='red', linewidth=2, label='Regression Line')

    # Adding labels and title
    plt.xlabel(x_col)
    plt.ylabel(y_col)
    plt.title(f"Regression Plot: {x_col} vs {y_col}")

    # Adding legend
    plt.legend()

    # Showing plot
    plt.show()

for col in columns:
    plot_regression(df, col, 'median_house_value')

"""# Analyzing of features Mean"""

for col in ['housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'median_income', 'median_house_value']:
    print(f"{col} Mean is : ", df[col].mean())

def estimate_mean(data, population_mean, confidence_level, sample_size=100, num_samples=100):
    sample_means = []
    # Sampling
    for _ in range(num_samples):
        sample = np.random.choice(data, size=sample_size, replace=True)
        sample_mean = np.mean(sample)
        sample_means.append(sample_mean)

    # Show results
    mean_of_means = np.mean(sample_means)
    std_of_means = np.std(sample_means, ddof=1)
    margin_of_error = stats.norm.ppf(0.95) * (std_of_means / np.sqrt(num_samples))
    confidence_interval = (mean_of_means - margin_of_error, mean_of_means + margin_of_error)

    print(f"Sample Means: {mean_of_means}")
    print(f"Actual Population Mean : {np.mean(data)}")
    print(f"Standard Deviation of Means: {std_of_means}")
    print(f"Margin of Error: {margin_of_error}")
    print(f"Confidence Interval: {confidence_interval}")


    # Hypothesis
    t_statistic, p_value = stats.ttest_1samp(sample_means, population_mean)

    # Determine if null hypothesis is rejected
    if p_value < (1 - confidence_level):
        hypothesis_result = "Reject null hypothesis"
    else:
        hypothesis_result = "Fail to reject null hypothesis"

    return t_statistic, p_value, hypothesis_result

estimate_mean(data=df['housing_median_age'], population_mean=28.63948, confidence_level= 0.95, sample_size=100, num_samples=100)

estimate_mean(data=df['median_house_value'], population_mean=28.63948, confidence_level= 0.95, sample_size=100, num_samples=100)

